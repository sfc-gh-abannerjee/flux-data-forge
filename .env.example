# =============================================================================
# Flux Data Forge - Environment Configuration
# =============================================================================
# Copy this file to .env and fill in your values.
# NEVER commit .env to version control!
# =============================================================================

# -----------------------------------------------------------------------------
# SNOWFLAKE CONFIGURATION (Required for SPCS deployment)
# -----------------------------------------------------------------------------
# Note: When running in SPCS, SNOWFLAKE_HOST and SNOWFLAKE_ACCOUNT are 
# automatically injected. These are only needed for local development.

SNOWFLAKE_DATABASE=MY_DATABASE
SNOWFLAKE_SCHEMA=MY_SCHEMA
SNOWFLAKE_WAREHOUSE=MY_WAREHOUSE
SNOWFLAKE_ROLE=SYSADMIN

# For local development only (not needed in SPCS)
# SNOWFLAKE_ACCOUNT=your_account_locator
# SNOWFLAKE_USER=your_username

# -----------------------------------------------------------------------------
# STREAMING TARGET TABLE
# -----------------------------------------------------------------------------
AMI_TABLE=AMI_STREAMING_READINGS
SERVICE_AREA=HOUSTON_METRO

# -----------------------------------------------------------------------------
# AWS CONFIGURATION (Optional - for S3 External Stage streaming)
# -----------------------------------------------------------------------------
# Only required if using the "Stage Landing (Raw JSON)" data flow option.
# This enables the medallion architecture: S3 → Snowpipe → Bronze table

# S3_BUCKET=your-bucket-name
# S3_PREFIX=raw/ami/
# AWS_REGION=us-west-2
# AWS_ROLE_ARN=arn:aws:iam::123456789012:role/your-role-name
# AWS_ACCESS_KEY_ID=your-access-key
# AWS_SECRET_ACCESS_KEY=your-secret-key

# -----------------------------------------------------------------------------
# POSTGRESQL CONFIGURATION (Optional - for Dual Write mode)
# -----------------------------------------------------------------------------
# Only required if using "Dual Write (SF + Postgres)" data flow option.
# Typically used with Snowflake Managed Postgres for operational dashboards.

# POSTGRES_HOST=your-postgres-host.snowflake.app
# POSTGRES_DATABASE=postgres
# POSTGRES_USER=application
# POSTGRES_PASSWORD=your-password
# POSTGRES_PORT=5432

# -----------------------------------------------------------------------------
# ADVANCED CONFIGURATION
# -----------------------------------------------------------------------------
# These have sensible defaults but can be overridden if needed.

# LOG_LEVEL=INFO
# BATCH_SIZE=100
# STREAMING_INTERVAL_SEC=10
